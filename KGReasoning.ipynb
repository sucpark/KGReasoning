{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ce8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "from models import KGReasoning\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from tensorboardX import SummaryWriter\n",
    "from dataloader import TestDataset, TrainDataset, SingledirectionalOneShotIterator\n",
    "from util import flatten_query, list2tuple, parse_time, set_global_seed, eval_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc311b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_name_dict = {('e',('r',)): '1p', \n",
    "                    ('e', ('r', 'r')): '2p',\n",
    "                    ('e', ('r', 'r', 'r')): '3p',\n",
    "                    (('e', ('r',)), ('e', ('r',))): '2i',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r',))): '3i',\n",
    "                    ((('e', ('r',)), ('e', ('r',))), ('r',)): 'ip',\n",
    "                    (('e', ('r', 'r')), ('e', ('r',))): 'pi',\n",
    "                    (('e', ('r',)), ('e', ('r', 'n'))): '2in',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r', 'n'))): '3in',\n",
    "                    ((('e', ('r',)), ('e', ('r', 'n'))), ('r',)): 'inp',\n",
    "                    (('e', ('r', 'r')), ('e', ('r', 'n'))): 'pin',\n",
    "                    (('e', ('r', 'r', 'n')), ('e', ('r',))): 'pni',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\n",
    "                    ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',)): 'up-DNF',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n',)): '2u-DM',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n', 'r')): 'up-DM'\n",
    "                }\n",
    "name_query_dict = {value: key for key, value in query_name_dict.items()}\n",
    "all_tasks = list(name_query_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1fd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args(args=None):\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Training and Testing Knowledge Graph Embedding Models',\n",
    "        usage='train.py [<args>] [-h | --help]'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('--cuda', action='store_true', help='use GPU')\n",
    "    \n",
    "    parser.add_argument('--do_train', action='store_true', help=\"do train\")\n",
    "    parser.add_argument('--do_valid', action='store_true', help=\"do valid\")\n",
    "    parser.add_argument('--do_test', action='store_true', help=\"do test\")\n",
    "\n",
    "    parser.add_argument('--data_path', type=str, default=None, help=\"KG data path\")\n",
    "    parser.add_argument('-n', '--negative_sample_size', default=128, type=int, help=\"negative entities sampled per query\")\n",
    "    parser.add_argument('-d', '--hidden_dim', default=500, type=int, help=\"embedding dimension\")\n",
    "    parser.add_argument('-g', '--gamma', default=12.0, type=float, help=\"margin in the loss\")\n",
    "    parser.add_argument('-b', '--batch_size', default=1024, type=int, help=\"batch size of queries\")\n",
    "    parser.add_argument('--test_batch_size', default=1, type=int, help='valid/test batch size')\n",
    "    parser.add_argument('-lr', '--learning_rate', default=0.0001, type=float)\n",
    "    parser.add_argument('-cpu', '--cpu_num', default=10, type=int, help=\"used to speed up torch.dataloader\")\n",
    "    parser.add_argument('-save', '--save_path', default=None, type=str, help=\"no need to set manually, will configure automatically\")\n",
    "    parser.add_argument('--max_steps', default=100000, type=int, help=\"maximum iterations to train\")\n",
    "    parser.add_argument('--warm_up_steps', default=None, type=int, help=\"no need to set manually, will configure automatically\")\n",
    "    \n",
    "    parser.add_argument('--save_checkpoint_steps', default=50000, type=int, help=\"save checkpoints every xx steps\")\n",
    "    parser.add_argument('--valid_steps', default=10000, type=int, help=\"evaluate validation queries every xx steps\")\n",
    "    parser.add_argument('--log_steps', default=100, type=int, help='train log every xx steps')\n",
    "    parser.add_argument('--test_log_steps', default=1000, type=int, help='valid/test log every xx steps')\n",
    "    \n",
    "    parser.add_argument('--nentity', type=int, default=0, help='DO NOT MANUALLY SET')\n",
    "    parser.add_argument('--nrelation', type=int, default=0, help='DO NOT MANUALLY SET')\n",
    "    \n",
    "    parser.add_argument('--geo', default='vec', type=str, choices=['vec', 'box', 'beta'], help='the reasoning model, vec for GQE, box for Query2box, beta for BetaE')\n",
    "    parser.add_argument('--print_on_screen', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--tasks', default='1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up', type=str, help=\"tasks connected by dot, refer to the BetaE paper for detailed meaning and structure of each task\")\n",
    "    parser.add_argument('--seed', default=0, type=int, help=\"random seed\")\n",
    "    parser.add_argument('-betam', '--beta_mode', default=\"(1600,2)\", type=str, help='(hidden_dim,num_layer) for BetaE relational projection')\n",
    "    parser.add_argument('-boxm', '--box_mode', default=\"(none,0.02)\", type=str, help='(offset activation,center_reg) for Query2box, center_reg balances the in_box dist and out_box dist')\n",
    "    parser.add_argument('--prefix', default=None, type=str, help='prefix of the log path')\n",
    "    parser.add_argument('--checkpoint_path', default=None, type=str, help='path for loading the checkpoints')\n",
    "    parser.add_argument('-evu', '--evaluate_union', default=\"DNF\", type=str, choices=['DNF', 'DM'], help='the way to evaluate union queries, transform it to disjunctive normal form (DNF) or use the De Morgan\\'s laws (DM)')\n",
    "\n",
    "    return parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8e2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39010289",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_path = 'data/FB15k-237-q2b'\n",
    "args.warm_up_steps = 10000\n",
    "args.geo = 'box'\n",
    "args.tasks = '1p.2i'\n",
    "args.do_train = True\n",
    "args.do_valid = True\n",
    "args.do_test = False\n",
    "args.cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5102b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8a9a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = args.tasks.split('.')\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b2f7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasks:\n",
    "    if 'n' in task and args.geo in ['box', 'vec']:\n",
    "        print('Q2B and GQE cannot handle queries with nagation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163bf9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.evaluate_union == 'DM':\n",
    "    assert args.geo == 'beta', \"only BetaE can support\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0072bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_time = parse_time()\n",
    "cur_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab338f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.prefix is None:\n",
    "    prefix = 'logs'\n",
    "else:\n",
    "    prefix = args.prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6fc06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.save_path = os.path.join(prefix, args.data_path.split('/')[-1], args.tasks, args.geo)\n",
    "args.save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0404dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.geo in ['box']:\n",
    "    tmp_str = \"g-{}-mode-{}\".format(args.gamma, args.box_mode)\n",
    "elif args.geo in ['vec']:\n",
    "    tmp_str = \"g-{}\".format(args.gamma)\n",
    "elif args.geo == 'beta':\n",
    "    tmp_str = \"g-{}-mode-{}\".format(args.gamma, args.beta_mode)\n",
    "tmp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c530d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.checkpoint_path is not None:\n",
    "    args.save_path = args.checkpoint_path\n",
    "else:\n",
    "    args.save_path = os.path.join(args.save_path, tmp_str, cur_time)\n",
    "args.save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dca37f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args.save_path):\n",
    "    os.makedirs(args.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a92a7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"logging to\", args.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "550b6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.do_train: # if not training, then create tensorboard files in some tmp location\n",
    "    writer = SummaryWriter('./logs-debug/unused-tb')\n",
    "else:\n",
    "    writer = SummaryWriter(args.save_path)\n",
    "writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7201cb95",
   "metadata": {},
   "source": [
    "### set_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0c78fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.do_train:\n",
    "    log_file = os.path.join(args.save_path, 'train.log')\n",
    "else:\n",
    "    log_file = os.path.join(args.save_path, 'test.log')\n",
    "log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a633097",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "        level=logging.INFO,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        filename=log_file,\n",
    "        filemode='a+'\n",
    "    )\n",
    "logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c7dbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.print_on_screen:\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a81cae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fab2cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/stats.txt'%args.data_path) as f:\n",
    "    entrel = f.readlines()\n",
    "    nentity = int(entrel[0].split(' ')[-1])\n",
    "    nrelation = int(entrel[1].split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7bf2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.nentity = nentity\n",
    "args.nrelation = nrelation\n",
    "\n",
    "print(f'# of entity: {args.nentity}, # of relation: {args.nrelation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb74e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('-------------------------------'*3)\n",
    "logging.info('Geo: %s' % args.geo)\n",
    "logging.info('Data Path: %s' % args.data_path)\n",
    "logging.info('#entity: %d' % nentity)\n",
    "logging.info('#relation: %d' % nrelation)\n",
    "logging.info('#max steps: %d' % args.max_steps)\n",
    "logging.info('Evaluate unoins using: %s' % args.evaluate_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae177f28",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9aa6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"loading data\")\n",
    "\n",
    "train_queries = pickle.load(open(os.path.join(args.data_path, \"train-queries.pkl\"), 'rb'))\n",
    "train_answers = pickle.load(open(os.path.join(args.data_path, \"train-answers.pkl\"), 'rb'))\n",
    "valid_queries = pickle.load(open(os.path.join(args.data_path, \"valid-queries.pkl\"), 'rb'))\n",
    "valid_hard_answers = pickle.load(open(os.path.join(args.data_path, \"valid-hard-answers.pkl\"), 'rb'))\n",
    "valid_easy_answers = pickle.load(open(os.path.join(args.data_path, \"valid-easy-answers.pkl\"), 'rb'))\n",
    "test_queries = pickle.load(open(os.path.join(args.data_path, \"test-queries.pkl\"), 'rb'))\n",
    "test_hard_answers = pickle.load(open(os.path.join(args.data_path, \"test-hard-answers.pkl\"), 'rb'))\n",
    "test_easy_answers = pickle.load(open(os.path.join(args.data_path, \"test-easy-answers.pkl\"), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80481a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_valid = list(valid_queries.keys())\n",
    "qs_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fcd21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_queries[qs_valid[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90ea5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(valid_easy_answers.keys())[50000])\n",
    "print(valid_easy_answers[list(valid_easy_answers.keys())[50000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78be1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(valid_hard_answers.keys())[50000])\n",
    "print(valid_hard_answers[list(valid_hard_answers.keys())[50000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfc78e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in all_tasks:\n",
    "    if 'u' in name:\n",
    "        name, evaluate_union = name.split('-')\n",
    "    else:\n",
    "        evaluate_union = args.evaluate_union\n",
    "    if name not in tasks or evaluate_union != args.evaluate_union:\n",
    "        query_structure = name_query_dict[name if 'u' not in name else '-'.join([name, evaluate_union])]\n",
    "        if query_structure in train_queries:\n",
    "            del train_queries[query_structure]\n",
    "        if query_structure in valid_queries:\n",
    "            del valid_queries[query_structure]\n",
    "        if query_structure in test_queries:\n",
    "            del test_queries[query_structure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9dae902",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Training info:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28eae9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_structure in train_queries:\n",
    "    logging.info(query_name_dict[query_structure]+\": \"+str(len(train_queries[query_structure])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81c53699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_queries = defaultdict(set)\n",
    "train_other_queries = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17eb2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = ['1p', '2p', '3p']\n",
    "\n",
    "for query_structure in train_queries:\n",
    "        if query_name_dict[query_structure] in path_list:\n",
    "            train_path_queries[query_structure] = train_queries[query_structure]\n",
    "        else:\n",
    "            train_other_queries[query_structure] = train_queries[query_structure]\n",
    "\n",
    "train_path_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8a7e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_queries = flatten_query(train_path_queries)\n",
    "train_path_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85e85699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
    "                            TrainDataset(train_path_queries, nentity, nrelation, args.negative_sample_size, train_answers),\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=args.cpu_num,\n",
    "                            collate_fn=TrainDataset.collate_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbf7d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(train_path_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8e78212",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0131e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.negative_sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58021875",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3970096",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baf4696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25227666",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(temp[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b5e71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_other_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1be23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "211a0cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_other_queries = flatten_query(train_other_queries)\n",
    "train_other_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f2fd2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_other_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
    "                            TrainDataset(train_other_queries, nentity, nrelation, args.negative_sample_size, train_answers),\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=args.cpu_num,\n",
    "                            collate_fn=TrainDataset.collate_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a352896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Validation info:\")\n",
    "if args.do_valid:\n",
    "    for query_structure in valid_queries:\n",
    "        logging.info(query_name_dict[query_structure]+\": \"+str(len(valid_queries[query_structure])))\n",
    "    valid_queries = flatten_query(valid_queries)\n",
    "    valid_dataloader = DataLoader(\n",
    "        TestDataset(\n",
    "            valid_queries, \n",
    "            args.nentity, \n",
    "            args.nrelation, \n",
    "        ), \n",
    "        batch_size=args.test_batch_size,\n",
    "        num_workers=args.cpu_num, \n",
    "        collate_fn=TestDataset.collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19721932",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KGReasoning(\n",
    "    nentity=nentity, \n",
    "    nrelation=nrelation, \n",
    "    hidden_dim=args.hidden_dim, \n",
    "    gamma=args.gamma, \n",
    "    geo=args.geo, \n",
    "    use_cuda = args.cuda, \n",
    "    box_mode=eval_tuple(args.box_mode), \n",
    "    beta_mode = eval_tuple(args.beta_mode), \n",
    "    test_batch_size=args.test_batch_size, \n",
    "    query_name_dict = query_name_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77422dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Parameter Configuration:')\n",
    "num_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\n",
    "    if param.requires_grad:\n",
    "        num_params += np.prod(param.size())\n",
    "        \n",
    "print('Parameter Number: %d' % num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "029c6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39bb02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.do_train:\n",
    "    current_learning_rate = args.learning_rate\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), \n",
    "        lr=current_learning_rate)\n",
    "    warm_up_steps = args.max_steps // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd5e5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.checkpoint_path is not None:\n",
    "    print('Loading checkpoint %s...' % args.checkpoint_path)\n",
    "    checkpoint = torch.load(os.path.join(args.checkpoint_path, 'checkpoint'))\n",
    "    init_step = checkpoint['step']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    if args.do_train:\n",
    "        current_learning_rate = checkpoint['current_learning_rate']\n",
    "        warm_up_steps = checkpoint['warm_up_steps']\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "else:\n",
    "    print('Ramdomly Initializing %s Model...' % args.geo)\n",
    "    init_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b14fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = init_step \n",
    "if args.geo == 'box':\n",
    "    print('box mode = %s' % args.box_mode)\n",
    "elif args.geo == 'beta':\n",
    "    print('beta mode = %s' % args.beta_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c53262ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tasks = %s' % args.tasks)\n",
    "print('init_step = %d' % init_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95d7db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.do_train:\n",
    "    print('Start Training...')\n",
    "    print('learning_rate = %d' % current_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1264f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('batch_size = %d' % args.batch_size)\n",
    "logging.info('hidden_dim = %d' % args.hidden_dim)\n",
    "logging.info('gamma = %f' % args.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9a04014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, save_variable_list, args):\n",
    "    '''\n",
    "    Save the parameters of the model and the optimizer,\n",
    "    as well as some other variables such as step and learning_rate\n",
    "    '''\n",
    "    \n",
    "    argparse_dict = vars(args)\n",
    "    with open(os.path.join(args.save_path, 'config.json'), 'w') as fjson:\n",
    "        json.dump(argparse_dict, fjson)\n",
    "\n",
    "    torch.save({\n",
    "        **save_variable_list,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()},\n",
    "        os.path.join(args.save_path, 'checkpoint')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed158d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(mode, step, metrics):\n",
    "    '''\n",
    "    Print the evaluation logs\n",
    "    '''\n",
    "    for metric in metrics:\n",
    "        logging.info('%s %s at step %d: %f' % (mode, metric, step, metrics[metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fadd86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step, writer):\n",
    "    '''\n",
    "    Evaluate queries in dataloader\n",
    "    '''\n",
    "    average_metrics = defaultdict(float)\n",
    "    all_metrics = defaultdict(float)\n",
    "\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\n",
    "    num_query_structures = 0\n",
    "    num_queries = 0\n",
    "    for query_structure in metrics:\n",
    "        log_metrics(mode+\" \"+query_name_dict[query_structure], step, metrics[query_structure])\n",
    "        for metric in metrics[query_structure]:\n",
    "            writer.add_scalar(\"_\".join([mode, query_name_dict[query_structure], metric]), metrics[query_structure][metric], step)\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\n",
    "            if metric != 'num_queries':\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\n",
    "        num_queries += metrics[query_structure]['num_queries']\n",
    "        num_query_structures += 1\n",
    "\n",
    "    for metric in average_metrics:\n",
    "        average_metrics[metric] /= num_query_structures\n",
    "        writer.add_scalar(\"_\".join([mode, 'average', metric]), average_metrics[metric], step)\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\n",
    "    log_metrics('%s average'%mode, step, average_metrics)\n",
    "\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6dd0d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.do_train:\n",
    "    training_logs = []\n",
    "        \n",
    "    # #Training Loop\n",
    "    for step in range(init_step, args.max_steps):\n",
    "        if step == 2*args.max_steps//3:\n",
    "            args.valid_steps *= 4\n",
    "\n",
    "        log = model.train_step(model, optimizer, train_path_iterator, args, step)\n",
    "        for metric in log:\n",
    "            print('path_'+metric, log[metric], step)\n",
    "        \n",
    "        if train_other_iterator is not None:\n",
    "            log = model.train_step(model, optimizer, train_other_iterator, args, step)\n",
    "            for metric in log:\n",
    "                print('other_'+metric, log[metric], step)\n",
    "            log = model.train_step(model, optimizer, train_path_iterator, args, step)\n",
    "\n",
    "        training_logs.append(log)\n",
    "\n",
    "        if step >= warm_up_steps:\n",
    "            current_learning_rate = current_learning_rate / 5\n",
    "            print('Change learning_rate to %f at step %d' % (current_learning_rate, step))\n",
    "            optimizer = torch.optim.Adam(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                lr=current_learning_rate)\n",
    "            warm_up_steps = warm_up_steps * 1.5\n",
    "            \n",
    "        if step % args.save_checkpoint_steps == 0:\n",
    "            save_variable_list = {\n",
    "                    'step': step, \n",
    "                    'current_learning_rate': current_learning_rate,\n",
    "                    'warm_up_steps': warm_up_steps}\n",
    "            save_model(model, optimizer, save_variable_list, args)\n",
    "\n",
    "        if step % args.valid_steps == 0 and step > 0:\n",
    "            if args.do_valid:\n",
    "                print('Evaluating on Valid Dataset...')\n",
    "                valid_all_metrics = evaluate(model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict, 'Valid', step, writer)\n",
    "\n",
    "            if args.do_test:\n",
    "                logging.info('Evaluating on Test Dataset...')\n",
    "                test_all_metrics = evaluate(model, test_easy_answers, test_hard_answers, args, test_dataloader, query_name_dict, 'Test', step, writer)\n",
    "                \n",
    "        if step % args.log_steps == 0:\n",
    "            metrics = {}\n",
    "            for metric in training_logs[0].keys():\n",
    "                metrics[metric] = sum([log[metric] for log in training_logs])/len(training_logs)\n",
    "\n",
    "            log_metrics('Training average', step, metrics)\n",
    "            training_logs = []\n",
    "\n",
    "    save_variable_list = {\n",
    "            'step': step, \n",
    "            'current_learning_rate': current_learning_rate,\n",
    "            'warm_up_steps': warm_up_steps\n",
    "        }\n",
    "    save_model(model, optimizer, save_variable_list, args)\n",
    "        \n",
    "try:\n",
    "    print (step)\n",
    "except:\n",
    "    step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a23cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.do_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e4253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
